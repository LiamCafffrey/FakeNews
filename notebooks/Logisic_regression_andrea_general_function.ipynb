{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import enchant\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true = pd.read_csv('../raw_data/True.csv')\n",
    "fake = pd.read_csv('../raw_data/Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true.drop(columns = ['subject','date'], inplace = True)\n",
    "fake.drop(columns = ['subject','date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true['score'] = 1\n",
    "fake['score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([true,fake],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text  score  \n",
       "0  WASHINGTON (Reuters) - The head of a conservat...      1  \n",
       "1  WASHINGTON (Reuters) - Transgender people will...      1  \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...      1  \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...      1  \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punc = string.punctuation + '“' + '”' + '’' + '‘'\n",
    "def remove_punctuation(text):\n",
    "    for punctuation in punc:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "data['title_clean']=data['title'].apply(remove_numbers)\n",
    "\n",
    "data['text_clean']=data['text'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation to title\n",
    "\n",
    "data['title_clean']=data['title_clean'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation to text\n",
    "\n",
    "data['text_clean']=data['text_clean'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stop words removal\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data['title_clean'] = data['title_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "data['text_clean'] = data['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Tokenize Text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return text.split()\n",
    "data['title_tokens']=data['title_clean'].apply(tokenize_text)\n",
    "data['text_tokens']=data['text_clean'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a function to find wrong words and return the count\n",
    "\n",
    "english = enchant.DictWithPWL(\"en_US\", \"vocab.txt\")\n",
    "wrong_words={}\n",
    "correct_words=set()\n",
    "def get_typos_t(tokens):\n",
    "     wrong_count=0\n",
    "     for token in tokens:\n",
    "            if token in wrong_words:\n",
    "                wrong_words[token]+=1\n",
    "                wrong_count+=1\n",
    "            else:\n",
    "                if not token in correct_words:    \n",
    "                    if not english.check(token) and not english.check(token.capitalize()):\n",
    "                        wrong_words[token]=1\n",
    "                        wrong_count+=1\n",
    "                    else:\n",
    "                        correct_words.add(token)\n",
    "     return wrong_count       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Defining a function to get tokens in text\n",
    "def get_tokens_text(df):\n",
    "    get_tokens = set()\n",
    "    for text in df['text']:\n",
    "        split_text = text.split()\n",
    "        for token in split_text:\n",
    "            get_tokens.add(token)\n",
    "    return get_tokens\n",
    "\n",
    "tokens_fake = get_tokens_text(fake)\n",
    "tokens_true = get_tokens_text(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(tokens_fake),len(tokens_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['title_token_count']=data['title_tokens'].apply(lambda tokens:len(tokens))\n",
    "data['text_token_count']=data['text_tokens'].apply(lambda tokens:len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['wrong_title_token_count']=data['title_tokens'].apply(get_typos_t)\n",
    "data['wrong_text_token_count']=data['text_tokens'].apply(get_typos_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['title_typo_ratio']= data['wrong_title_token_count']/data['title_token_count']\n",
    "data['text_typo_ratio']= data['wrong_text_token_count']/data['text_token_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x=\"score\", y=\"title_typo_ratio\", hue=\"score\", style=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x=\"score\", y=\"text_typo_ratio\", hue=\"score\", style=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_clean = data[['title', 'text', 'title_clean', 'text_clean','title_tokens',\n",
    "       'text_tokens','text_typo_ratio', 'score']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Generic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(data):\n",
    "    data['title_clean']=data['title'].apply(remove_numbers)\n",
    "    data['text_clean']=data['text'].apply(remove_numbers)\n",
    "    \n",
    "    data['title_clean']=data['title_clean'].apply(remove_punctuation)\n",
    "    data['text_clean']=data['text_clean'].apply(remove_punctuation)\n",
    "    \n",
    "    data['title_clean'] = data['title_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "    data['text_clean'] = data['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "    \n",
    "    data['title_tokens']=data['title_clean'].apply(tokenize_text)\n",
    "    data['text_tokens']=data['text_clean'].apply(tokenize_text)\n",
    "    \n",
    "    data['title_token_count']=data['title_tokens'].apply(lambda tokens:len(tokens))\n",
    "    data['text_token_count']=data['text_tokens'].apply(lambda tokens:len(tokens))\n",
    "    \n",
    "    data['wrong_title_token_count']=data['title_tokens'].apply(get_typos_t)\n",
    "    data['wrong_text_token_count']=data['text_tokens'].apply(get_typos_t)\n",
    "    \n",
    "    data['title_typo_ratio']= data['wrong_title_token_count']/data['title_token_count']\n",
    "    data['text_typo_ratio']= data['wrong_text_token_count']/data['text_token_count']\n",
    "    \n",
    "    return data[['title_clean', 'text_clean','text_typo_ratio']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_light(data):\n",
    "    data['title_clean']=data['title'].apply(remove_numbers)\n",
    "    data['text_clean']=data['text'].apply(remove_numbers)\n",
    "    \n",
    "    data['title_clean']=data['title_clean'].apply(remove_punctuation)\n",
    "    data['text_clean']=data['text_clean'].apply(remove_punctuation)\n",
    "    \n",
    "    data['title_clean'] = data['title_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "    data['text_clean'] = data['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "    \n",
    "    data['title_tokens']=data['title_clean'].apply(tokenize_text)\n",
    "    data['text_tokens']=data['text_clean'].apply(tokenize_text)\n",
    "    \n",
    "    data['title_token_count']=data['title_tokens'].apply(lambda tokens:len(tokens))\n",
    "    data['text_token_count']=data['text_tokens'].apply(lambda tokens:len(tokens))\n",
    "    \n",
    "    data['wrong_title_token_count']=data['title_tokens'].apply(get_typos_t)\n",
    "    data['wrong_text_token_count']=data['text_tokens'].apply(get_typos_t)\n",
    "    \n",
    "    data['title_typo_ratio']= data['wrong_title_token_count']/data['title_token_count']\n",
    "    data['text_typo_ratio']= data['wrong_text_token_count']/data['text_token_count']\n",
    "    \n",
    "    data['title_clean']=data['title']\n",
    "    data['text_clean']=data['text_clean']\n",
    "    \n",
    "    return data[['title_clean', 'text_clean','text_typo_ratio']]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = ['title', 'text', 'title_clean', 'text_clean','title_tokens',\n",
    "#        'text_tokens','text_typo_ratio']\n",
    "feature_cols = ['title_clean', 'text_clean','text_typo_ratio']\n",
    "\n",
    "x=data_clean[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_typo_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33958</th>\n",
       "      <td>BREAKING FINALLY New Wikileaks Email…We going ...</td>\n",
       "      <td>latest Wikileaks email evidence smoke Hillary ...</td>\n",
       "      <td>0.092391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>German liberals would expect finance ministry ...</td>\n",
       "      <td>BERLIN Reuters Germany Free Democrats FDP woul...</td>\n",
       "      <td>0.117302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25814</th>\n",
       "      <td>Trump LOSES Complete Nervous Breakdown Worst W...</td>\n",
       "      <td>Trump bad week First humiliated front millions...</td>\n",
       "      <td>0.049020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18689</th>\n",
       "      <td>Merkel Macron pledge lead EU forward postBrexit</td>\n",
       "      <td>TALLINN Reuters French President Emmanuel Macr...</td>\n",
       "      <td>0.054670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44673</th>\n",
       "      <td>AMERICAN TRAGEDY Really Killed JonBenét Ramsey</td>\n",
       "      <td>roses know thorns hurt quote attributed JonBen...</td>\n",
       "      <td>0.075447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_clean  \\\n",
       "33958  BREAKING FINALLY New Wikileaks Email…We going ...   \n",
       "19813  German liberals would expect finance ministry ...   \n",
       "25814  Trump LOSES Complete Nervous Breakdown Worst W...   \n",
       "18689    Merkel Macron pledge lead EU forward postBrexit   \n",
       "44673     AMERICAN TRAGEDY Really Killed JonBenét Ramsey   \n",
       "\n",
       "                                              text_clean  text_typo_ratio  \n",
       "33958  latest Wikileaks email evidence smoke Hillary ...         0.092391  \n",
       "19813  BERLIN Reuters Germany Free Democrats FDP woul...         0.117302  \n",
       "25814  Trump bad week First humiliated front millions...         0.049020  \n",
       "18689  TALLINN Reuters French President Emmanuel Macr...         0.054670  \n",
       "44673  roses know thorns hurt quote attributed JonBen...         0.075447  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('vectorizer_title', CountVectorizer(), 'title_clean'),\n",
    "    ('vectorizer_text', CountVectorizer(), 'text_clean'),\n",
    "\n",
    "    #insert function here\n",
    "    \n",
    "    \n",
    "])\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('Logistic', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreamontagnoli/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('vectorizer_title', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', ...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971789161098737"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= '''President Donald Trump is trying to steal a free and fair election that he lost by a wide margin to President-elect Joe Biden by tearing at the most basic principle of American democracy: He's trying to throw out hundreds of thousands of votes.\n",
    "Trump's latest escalation of his attempt to subvert the result of the election followed a string of knock-backs in the courts and after a statewide audit in Georgia confirmed Biden's victory in the crucial swing state.\n",
    "He asked state Republican leaders in Michigan to visit him Friday, hinting at a possible attempt to convince them to ignore Biden's big win in the state and send a slate of electors to the Electoral College that backs him and not the President-elect. Both Michigan House Speaker Lee Chatfield and Senate Majority Leader Mike Shirkey will meet with Trump at the White House at 4 p.m. ET, according to a source familiar with the plans.\n",
    "This follows the President's calls to two Wayne County GOP officials, who are now seeking to take back their votes to certify Biden's victory.\n",
    "Trump's lawyer, Rudy Giuliani, who rampaged through an unhinged news conference Thursday, is in effect baselessly arguing that troves of Democratic mail-in ballots, many of them cast by Black voters, are illegal and that Trump has therefore won the election with room to spare.\n",
    "\"It changes the result of the election in Michigan if you take out Wayne County,\" Giuliani said at a crowded, mask-free and delusional news conference featuring Trump's crew of TV lawyers in Washington.\n",
    "Giuliani's team is also making absurd claims of a massive, centralized, Democratic conspiracy involving long-dead Venezuelan dictator Hugo Chavez, Cuba, China, the Clinton Foundation and George Soros to throw the election.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=\"Trump undercuts American democracy as he clings to power\"\n",
    "test_series=pd.Series(test)\n",
    "title_series=pd.Series(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.DataFrame({'title_clean':title_series,'text_clean':test_series, 'text_typo_ratio':[0.1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test = pd.read_csv('../raw_data/fake_extra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_test = fake_test.replace(np.nan, '', regex=True)\n",
    "fake_test=fake_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result=final_pipe.predict(preparation(fake_test))\n",
    "result=final_pipe.predict(preparation_light(fake_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4538, 1: 164}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(result, return_counts=True)\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dirty logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y=data['score']\n",
    "\n",
    "# feature_cols = ['title', 'text', 'title_clean', 'text_clean','title_tokens',\n",
    "#        'text_tokens','text_typo_ratio']\n",
    "feature_cols = ['title', 'text','text_typo_ratio']\n",
    "\n",
    "x_dirty=data_clean[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_dirty,y,random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('vectorizer_title', CountVectorizer(), 'title'),\n",
    "    ('vectorizer_text', CountVectorizer(), 'text'),\n",
    "\n",
    "])\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('Logistic', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
