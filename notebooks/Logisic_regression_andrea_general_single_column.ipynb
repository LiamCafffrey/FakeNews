{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import enchant\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = pd.read_csv('../raw_data/True.csv')\n",
    "fake = pd.read_csv('../raw_data/Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true.drop(columns = ['subject','date'], inplace = True)\n",
    "fake.drop(columns = ['subject','date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['score'] = 1\n",
    "fake['score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([true,fake],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '/Getty Images'\n",
    "stop_words =['/Getty Images']\n",
    "pat = '|'.join(r\"\\b{}\\b\".format(x) for x in stop_words)\n",
    "data['text'] = data['text'].str.replace(pat, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text  score  \n",
       "0  WASHINGTON (Reuters) - The head of a conservat...      1  \n",
       "1  WASHINGTON (Reuters) - Transgender people will...      1  \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...      1  \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...      1  \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punc = string.punctuation + '“' + '”' + '’' + '‘'\n",
    "def remove_punctuation(text):\n",
    "    for punctuation in punc:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "data['title_text_clean']=data['title']+data['text']\n",
    "\n",
    "data['title_text_clean']=data['title_text_clean'].apply(remove_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation to text\n",
    "\n",
    "data['title_text_clean']=data['title_text_clean'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words removal\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data['title_text_clean'] = data['title_text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize Text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return text.split()\n",
    "data['title_text_tokens']=data['title_text_clean'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find wrong words and return the count\n",
    "\n",
    "english = enchant.DictWithPWL(\"en_US\", \"vocab.txt\")\n",
    "wrong_words={}\n",
    "correct_words=set()\n",
    "def get_typos_t(tokens):\n",
    "     wrong_count=0\n",
    "     for token in tokens:\n",
    "            if token in wrong_words:\n",
    "                wrong_words[token]+=1\n",
    "                wrong_count+=1\n",
    "            else:\n",
    "                if not token in correct_words:    \n",
    "                    if not english.check(token) and not english.check(token.capitalize()):\n",
    "                        wrong_words[token]=1\n",
    "                        wrong_count+=1\n",
    "                    else:\n",
    "                        correct_words.add(token)\n",
    "     return wrong_count       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to get tokens in text\n",
    "def get_tokens_text(df):\n",
    "    get_tokens = set()\n",
    "    for text in df['text']:\n",
    "        split_text = text.split()\n",
    "        for token in split_text:\n",
    "            get_tokens.add(token)\n",
    "    return get_tokens\n",
    "\n",
    "tokens_fake = get_tokens_text(fake)\n",
    "tokens_true = get_tokens_text(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokens_fake),len(tokens_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['title_text_token_count']=data['title_text_tokens'].apply(lambda tokens:len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['wrong_title_text_token_count']=data['title_text_tokens'].apply(get_typos_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['title_text_typo_ratio']= data['wrong_title_text_token_count']/data['title_text_token_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x=\"score\", y=\"title_typo_ratio\", hue=\"score\", style=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x=\"score\", y=\"text_typo_ratio\", hue=\"score\", style=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data[['title_text_clean', 'title_text_typo_ratio', 'score']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Generic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(data):\n",
    "    data['title_text_clean']=data['title']+data['text']\n",
    "    \n",
    "    data['title_text_clean']=data['title_text_clean'].apply(remove_numbers)\n",
    "    \n",
    "    data['title_text_clean']=data['title_text_clean'].apply(remove_punctuation)\n",
    "    \n",
    "    data['title_text_clean'] = data['title_text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "    \n",
    "    data['title_text_tokens']=data['title_text_clean'].apply(tokenize_text)\n",
    "    \n",
    "    data['title_text_token_count']=data['title_text_tokens'].apply(lambda tokens:len(tokens))\n",
    "    \n",
    "    data['wrong_title_text_tokens']=data['title_text_tokens'].apply(get_typos_t)\n",
    "    \n",
    "    data['title_text_typo_ratio']= data['wrong_title_text_tokens']/data['title_text_token_count']\n",
    "    \n",
    "    return data[['title_text_clean','title_text_typo_ratio']]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = ['title', 'text', 'title_clean', 'text_clean','title_tokens',\n",
    "#        'text_tokens','text_typo_ratio']\n",
    "feature_cols = ['title_text_clean','title_text_typo_ratio']\n",
    "\n",
    "x=data_clean[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text_clean</th>\n",
       "      <th>title_text_typo_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33958</th>\n",
       "      <td>BREAKING FINALLY New Wikileaks Email…We going ...</td>\n",
       "      <td>0.095745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>German liberals would expect finance ministry ...</td>\n",
       "      <td>0.120690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25814</th>\n",
       "      <td>Trump LOSES Complete Nervous Breakdown Worst W...</td>\n",
       "      <td>0.052133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18689</th>\n",
       "      <td>Merkel Macron pledge lead EU forward postBrexi...</td>\n",
       "      <td>0.058427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44673</th>\n",
       "      <td>AMERICAN TRAGEDY Really Killed JonBenét Ramsey...</td>\n",
       "      <td>0.075625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title_text_clean  \\\n",
       "33958  BREAKING FINALLY New Wikileaks Email…We going ...   \n",
       "19813  German liberals would expect finance ministry ...   \n",
       "25814  Trump LOSES Complete Nervous Breakdown Worst W...   \n",
       "18689  Merkel Macron pledge lead EU forward postBrexi...   \n",
       "44673  AMERICAN TRAGEDY Really Killed JonBenét Ramsey...   \n",
       "\n",
       "       title_text_typo_ratio  \n",
       "33958               0.095745  \n",
       "19813               0.120690  \n",
       "25814               0.052133  \n",
       "18689               0.058427  \n",
       "44673               0.075625  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('vectorizer_title_text', CountVectorizer(), 'title_text_clean'),\n",
    "    \n",
    "])\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('Logistic', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreamontagnoli/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('vectorizer_title_text', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933927245731254"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= '''President Donald Trump is trying to steal a free and fair election that he lost by a wide margin to President-elect Joe Biden by tearing at the most basic principle of American democracy: He's trying to throw out hundreds of thousands of votes.\n",
    "Trump's latest escalation of his attempt to subvert the result of the election followed a string of knock-backs in the courts and after a statewide audit in Georgia confirmed Biden's victory in the crucial swing state.\n",
    "He asked state Republican leaders in Michigan to visit him Friday, hinting at a possible attempt to convince them to ignore Biden's big win in the state and send a slate of electors to the Electoral College that backs him and not the President-elect. Both Michigan House Speaker Lee Chatfield and Senate Majority Leader Mike Shirkey will meet with Trump at the White House at 4 p.m. ET, according to a source familiar with the plans.\n",
    "This follows the President's calls to two Wayne County GOP officials, who are now seeking to take back their votes to certify Biden's victory.\n",
    "Trump's lawyer, Rudy Giuliani, who rampaged through an unhinged news conference Thursday, is in effect baselessly arguing that troves of Democratic mail-in ballots, many of them cast by Black voters, are illegal and that Trump has therefore won the election with room to spare.\n",
    "\"It changes the result of the election in Michigan if you take out Wayne County,\" Giuliani said at a crowded, mask-free and delusional news conference featuring Trump's crew of TV lawyers in Washington.\n",
    "Giuliani's team is also making absurd claims of a massive, centralized, Democratic conspiracy involving long-dead Venezuelan dictator Hugo Chavez, Cuba, China, the Clinton Foundation and George Soros to throw the election.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title=\"Trump undercuts American democracy as he clings to power\"\n",
    "# test_series=pd.Series(test)\n",
    "# title_series=pd.Series(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df=pd.DataFrame({'title_clean':title_series,'text_clean':test_series, 'text_typo_ratio':[0.1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test = pd.read_csv('../raw_data/fake_extra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_test = fake_test.replace(np.nan, '', regex=True)\n",
    "fake_test=fake_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result=final_pipe.predict(preparation(fake_test))\n",
    "result=final_pipe.predict(preparation(fake_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4482, 1: 220}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(result, return_counts=True)\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dirty logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y=data['score']\n",
    "\n",
    "# feature_cols = ['title', 'text', 'title_clean', 'text_clean','title_tokens',\n",
    "#        'text_tokens','text_typo_ratio']\n",
    "feature_cols = ['title', 'text','text_typo_ratio']\n",
    "\n",
    "x_dirty=data_clean[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_dirty,y,random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('vectorizer_title', CountVectorizer(), 'title'),\n",
    "    ('vectorizer_text', CountVectorizer(), 'text'),\n",
    "\n",
    "])\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('Logistic', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
